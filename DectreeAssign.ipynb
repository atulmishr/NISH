{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ques-1\n",
    "#import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  1  1.1  1.2  1.3\n",
       "0  R  1    1    1    2\n",
       "1  R  1    1    1    3\n",
       "2  R  1    1    1    4\n",
       "3  R  1    1    1    5\n",
       "4  R  1    1    2    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the Dataset & head,shape\n",
    "dc=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data')\n",
    "dc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tst\n",
    "train,test = tst(dc,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.loc[:,train.columns != 'B']\n",
    "test_x = test.loc[:,test.columns != 'B']\n",
    "\n",
    "train_y = train['B']\n",
    "test_y = test['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#model=DTC()\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual Predicted\n",
      "381      R         R\n",
      "311      B         R\n",
      "271      R         R\n",
      "21       R         R\n",
      "521      R         R\n",
      "281      B         L\n",
      "173      R         R\n",
      "48       R         R\n",
      "144      R         R\n",
      "612      L         L\n",
      "490      L         L\n",
      "61       R         R\n",
      "113      R         R\n",
      "453      L         L\n",
      "160      R         B\n",
      "615      L         L\n",
      "491      L         L\n",
      "305      L         L\n",
      "346      R         B\n",
      "563      B         R\n",
      "347      R         R\n",
      "261      R         R\n",
      "394      R         B\n",
      "574      L         L\n",
      "485      L         L\n",
      "577      L         L\n",
      "122      R         R\n",
      "229      L         L\n",
      "241      R         R\n",
      "376      L         B\n",
      "..     ...       ...\n",
      "474      L         L\n",
      "47       R         R\n",
      "14       R         R\n",
      "340      L         L\n",
      "556      L         L\n",
      "212      R         R\n",
      "325      L         L\n",
      "303      L         L\n",
      "440      L         L\n",
      "395      R         R\n",
      "592      L         B\n",
      "426      L         L\n",
      "26       R         B\n",
      "242      R         R\n",
      "313      R         R\n",
      "607      L         L\n",
      "390      R         R\n",
      "270      R         R\n",
      "277      L         L\n",
      "240      L         L\n",
      "38       R         R\n",
      "124      L         B\n",
      "283      R         R\n",
      "62       R         R\n",
      "12       R         R\n",
      "588      L         L\n",
      "372      R         R\n",
      "168      R         R\n",
      "554      L         L\n",
      "193      R         R\n",
      "\n",
      "[188 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "finres = pd.DataFrame({'Actual': test_y,'Predicted' : pred_y})\n",
    "print(finres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7  4]\n",
      " [11 83  0]\n",
      " [11  2 69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.04      0.08      0.06        12\n",
      "          L       0.90      0.88      0.89        94\n",
      "          R       0.95      0.84      0.89        82\n",
      "\n",
      "avg / total       0.87      0.81      0.84       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm, classification_report as clr\n",
    "print(cm(test_y,pred_y))\n",
    "print(clr(test_y,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A final Accuracy Score is : 0.824468085106\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score = accuracy_score(test_y,pred_y)\n",
    "print(\"A final Accuracy Score is : {}\".format(accuracy_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
